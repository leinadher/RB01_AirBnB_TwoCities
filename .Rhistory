subtitle = "Barcelona") +
theme(axis.text.x = element_text()) +
theme_minimal()
top_hosts <- Barcelona_md %>%
distinct(host_id, .keep_all = TRUE) %>%
arrange(desc(calculated_host_listings_count)) %>%
slice_head(n = 5)
# Create the ggplot2 horizontal barplot
ggplot(top_hosts, aes(x = reorder(host_name, calculated_host_listings_count),
y = calculated_host_listings_count)) +
geom_bar(stat = "identity",
fill = "#f1796f") +
geom_text(aes(label = calculated_host_listings_count),
hjust = 0,
color = "black",
size = 3) +
labs(title = "Top 5 hosts by number of listings",
subtitle = "Barcelona",
x = "",
y = "Listing count") +
coord_flip() + # Flip the plot to horizontal bars
theme_minimal() +
theme(axis.text.x = element_text(angle = 0, hjust = 1))
top_hosts <- Barcelona_md %>%
distinct(host_id, .keep_all = TRUE) %>%
arrange(desc(calculated_host_listings_count)) %>%
slice_head(n = 5)
# Create the ggplot2 horizontal barplot
ggplot(top_hosts, aes(x = reorder(host_name, calculated_host_listings_count),
y = calculated_host_listings_count)) +
geom_bar(stat = "identity",
fill = "#f1796f") +
geom_text(aes(label = calculated_host_listings_count),
hjust = 0,
color = "black",
size = 3) +
labs(title = "Top 5 hosts by number of listings",
subtitle = "Barcelona",
x = "",
y = "Listing count") +
coord_flip() + # Flip the plot to horizontal bars
theme_minimal() +
theme(axis.text.x = element_text(angle = 0, hjust = 1))
knitr::opts_chunk$set(echo = TRUE)
lm(price ~ star_rating, data = Barcelona_md)
data(co2)
data(co2)
co2.stl <- stl(co2, s.window = "periodic")
plot(co2.stl)
# 4) gam.xray -- 16% TRUE ??
xray.gam.acc <- cbind(
predict(gam.xray, type = "response"),
d.xray["disease"]
)
set.seed(10)
##### Packages #####
library(tidyverse)    # Data manipulation and visualization
library(kernlab)      # SVM methodology
library(e1071)        # SVM methodology
library(ISLR)         # Contains example data set
library(RColorBrewer) # Customized colors for plots
# Construct sample data set - completely separated
x <- matrix(rnorm(20*2), ncol = 2)
y <- c(rep(-1,10), rep(1,10))
x[y==1,] <- x[y==1,] + 2
dat <- data.frame(x=x, y=as.factor(y))
# Plot data
ggplot(
data = dat,
aes(x = x.2, y = x.1, color = y, shape = y)
) +
geom_point(size = 2) +
scale_color_manual(values=c("#000000", "#FF0000")) +
theme(legend.position = "none")
## Using the e1071 package
# Fit Support Vector Machine model to data set
svmfit <- svm(
y~., data = dat,
kernel = "linear", scale = FALSE,
cost = 1e10
)
# Plot Results
plot(svmfit, dat)
plot(t.yields)
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
r.burg$resid
str(r.burg
str(r.burg)
str(r.burg)
plot(resid)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
plot(resid)
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
par(mfrow = c(1, 1))
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
par(mfrow = c(1, 1))
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
## d)
str(r.mle <- ar(t.yields, method = "mle", order.max = 1))
r.mle <- arima(yields, order = c(1, 0, 0), include.mean = T)
r.mle
# The following will indicate if the algorithm has converged
r.mle$code
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
##### EXERCISE 6.1 #####
## a)
yields <- read.table("http://stat.ethz.ch/Teaching/Datasets/WBL/yields.dat",
header = FALSE)
t.yields <- ts(yields[, 1])
# Could the data be generated by an AR-process? What is the order p?
# Look at acf() and pacf()
# We plot the time series
plot(t.yields)
# It seems to be stationary, but mean is not 0 an must be shifted AR(p)
# Let's look at acf and pacf
par(mfrow = c(1, 2))
acf(t.yields, ylim = c(-1, 1))
pacf(t.yields, ylim = c(-1, 1))
# The exponential decay in the acf shows it may be an AR
# From the pacf we conclude p=1
# Xt − μ = α1(Xt−1 − μ) + Et
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
## c)
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
par(mfrow = c(1, 1))
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
## d)
str(r.mle <- ar(t.yields, method = "mle", order.max = 1))
r.mle <- arima(yields, order = c(1, 0, 0), include.mean = T)
r.mle
# The following will indicate if the algorithm has converged
r.mle$code
# 0 means there has been convergence
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
source("~/HSLU/24.1 Second Semester/W.MSCIDS_RTP02.F24 - Discrete Response, Time Series and Panel Data/Exercises/Exercise_06/Exercise-06.R", echo=TRUE)
## b)
# Using the autocorrelations, compute the Yule-Walker estimate of α by hand.
# Recall the Yule-Walker equation for the estimated autocorrelation function at
# lag 1 reads:
#  ˆρ(1) = α · ˆρ (0)
# Yule Walker equation: p(0) = 1
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
# We execute the following to get α alue at lag = 1.
acf(t.yields, plot = FALSE)
# At lag = 1 it is -0.39
# For order.max use the order p you have detected in a).
r.yw <- ar(t.yields, method = "yw", order.max = 1)
r.yw$ar
# Let's look at the variables of the yw object:
str(r.yw)
# The mean of the distribution is included in it, same as mean(t.yields):
r.yw$x.mean
# Innovation variance:
r.yw$var.pred
# Compute parameters of the AR model using Burg method. Check residuals
r.burg <- ar(t.yields, method = "burg", order.max = 1)
# We look at residuals
resid <- r.burg$resid
# Let's look at the variables of the yw object:
str(r.burg)
par(mfrow = c(1, 1))
plot(resid)
par(mfrow = c(1, 2))
acf(resid, na.action = na.omit)
pacf(resid, na.action = na.omit)
par(mfrow = c(1, 1))
## d)
str(r.mle <- ar(t.yields, method = "mle", order.max = 1))
r.mle <- arima(yields, order = c(1, 0, 0), include.mean = T)
r.mle
# The following will indicate if the algorithm has converged
r.mle$code
install.packages(c("randomForest", "xgboost", "Ckmeans.1d.dp", "ggplot2", "MVA", "ROCR", "mclust", "dbscan"))
install.packages(c("randomForest", "xgboost", "Ckmeans.1d.dp", "ggplot2", "MVA", "ROCR", "mclust", "dbscan"))
install.packages(c("randomForest", "xgboost", "Ckmeans.1d.dp", "ggplot2", "MVA", "ROCR", "mclust", "dbscan"))
install.packages("randomForest")
install.packages("xboost")
install.packages("Ckmeans.1d.dp")
install.packages("MVA")
install.packages("ROCR")
install.packages("mclust")
install.packages("dbscan")
plot(diff(log(AirPassengers), lag=12))
plot(diff(diff(log(AirPassengers), lag=12)))
plot(AirPassengers)
# 11.04.2024
plot(AirPassengers)
# We differenciate to remove trend
plot(diff(log(AirPassengers), lag=12))
plot(diff(diff(log(AirPassengers), lag=12)))
library(fpp)
lsunspot100 <- window(log(sunspotarea), start = 1875,
end = 1974)
install.packages("fpp")
library(fpp)
lsunspot100 <- window(log(sunspotarea), start = 1875,
end = 1974)
fit.ar10 <- arima(lsunspot100, order = c(10, 0, 0))
# 25.04.2024
#### EXERCISE 10.1 ####
library(fpp)
lsunspot100 <- window(log(sunspotarea), start = 1875,
end = 1974)
fit.ar10 <- arima(lsunspot100, order = c(10, 0, 0))
# Notice it is an ARIMA model, since it has trend + periodicity
## Predict next 100 observations in logged model, plot along with mean
# We use the above fit for an arima(10) model
pred <- predict(fit.ar10, n.ahead = 100)
# Plotting the logged time series
plot(lsunspot100, xlim = c(1875, 2074),
main = "Logged time series + forecast")
# Plotting the mean
abline(h = fit.ar10$coef["intercept"], lty = 2)
# Plotting the forecast
lines(pred$pred, col = "darkseagreen", lw = 2)
## Compare the last 37 observations with the forecast for those points
## Add confidence intervals to plot
pred37 <- predict(fit.ar10, n.ahead = 37)
plot(log(sunspotarea), ylim = c(2, 9))
lines(pred37$pred, col = "darkseagreen", lwd = 2)
lines(pred37$pred + 1.96 * pred37$se, col = "darkseagreen",
lty = 2)
lines(pred37$pred - 1.96 * pred37$se, col = "darkseagreen",
lty = 2)
## Sum of squares
# Subtracting the model to the actual data across the entire window
pred.error <- window(log(sunspotarea), start = 1975,
end = 2011) - pred37$pred
# Mean of the squared result (sum of squares)
(pred.mse <- mean(pred.error^2))
#### EXERCISE 10.2 ####
library(forecast)
d.air <- AirPassengers
d.airshort <- window(d.air, end = c(1956, 12))
d.airshort1 <- log(d.airshort)
d.airshort2 <- diff(d.airshort1, lag = 12)
d.airshort3 <- diff(d.airshort2, lag = 1)
tsdisplay(d.airshort3, points = FALSE)
# Based on the correlograms, we assume that
# SARIMA(0, 1, 1)(0, 1, 1)^12
# Is a valid model
s1.air <- arima(d.airshort1, order = c(0, 1, 1), seasonal = c(0, 1, 1))
s1.air
# We look at the residuals
tsdisplay(s1.air$residuals, points = FALSE)
# Using the model, we produce the prediction
t.pr.sarima <- predict(s1.air, n.ahead = 48)
plot(log(d.air), xlim = c(1950, 1961), ylim = c(4.5,
7.5))
t.u <- t.pr.sarima$pred + 1.96 * t.pr.sarima$se
t.l <- t.pr.sarima$pred - 1.96 * t.pr.sarima$se
lines(t.pr.sarima$pred, col = "darkred", lw = 2)
lines(t.u, col = "darkred", lty = 2)
lines(t.l, col = "darkred", lty = 2)
## Using trend exploration
fit <- stl(d.airshort1, s.window = "periodic")
trend <- fit$time.series[, 2]
# Least Squares for trend over the last 4 years
yy <- window(trend, start = c(1953, 1))
xx <- time(yy)
reg <- lm(yy ~ xx)
# Trend Extrapolation
kk <- 48
trend.ex <- rev(trend)[1] + ((1:kk)/12) * coef(reg)[2]
## seasonality
saison <- fit$time.series[, 1]
saisy <- window(saison, start = c(1953, 1))
sais.ex <- ts(saisy, start = c(1957, 1), end = c(1960, 12),
frequency = 12)
## remainder
remainder <- fit$time.series[, 3]
tsdisplay(remainder, points = FALSE)
# Because the remainder behaves like an AR(3) model
fit.rem <- arima(remainder, order = c(3, 0, 0))
tsdisplay(resid(fit.rem), points = FALSE)
# Residuals are in order, we may produce the forecast
pred <- predict(fit.rem, n.ahead = 48)
rem.ex <- pred$pred
## everything together
series.ex <- trend.ex + sais.ex + rem.ex
## Plotting
plot(log(d.air), xlim = c(1950, 1961), ylim = c(4.5,
7.5))
lines(series.ex, col = "red", lwd = 2)
## Model comparison
ts.air.forecast <- window(log(d.air), start = c(1957,
1), end = c(1960, 12))
# SARIMA
mean((ts.air.forecast - t.pr.sarima$pred)^2)
# STL
mean((ts.air.forecast - series.ex)^2)
setwd("~/GitHub/RB01_AirBnB_TwoCities")
